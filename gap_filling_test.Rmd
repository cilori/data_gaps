---
title: "Gap filling with metR::ImputeEOF"
date: "`r Sys.Date()`"
output: 
  flexdashboard::flex_dashboard:
    vertical_layout: scroll
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width=16, fig.height=10)
library(dplyr)
library(fst)
library(data.table)
library(oceancolouR)
library(ggplot2)
library(raster)
library(gridExtra)
library(lubridate)
library(latticeExtra)
library(sp)
library(lmodel2)
library(broom)
library(gridExtra)
library(geodist)
library(patchwork)
source("gap_filling_test_functions.R")
data("wrld_simpl", package = "maptools")

data("nwa_bins_4km")
data("nwa_lats_4km")
data("nwa_lons_4km")

lats <- range(nwa_lats_4km)
lons <- range(nwa_lons_4km)

sensor <- "MODIS"
year <- 2015
days <- c(53, 172)
weeks <- c(9, 22)
low_percov <- 5
num_years <- 0
low_chla <- 0
high_chla <- 64

# maximum distance allowed between satellite pixel and in situ measurement (in metres)
max_is_dist <- 10000


#*******************************************************************************
# prepare in situ matchup data

in_situ_file <- "../satellite_validation/01_in_situ_data/HPLC_1997-2020_20201110.csv"
in_situ_df <- read.csv(in_situ_file, header=TRUE) %>%
  dplyr::filter(YEAR==year) %>%
  dplyr::mutate(cruise_id = as.character(cruise_id)) %>%
  dplyr::select(ID, DEPTH, LATDEC, LONGDEC, YEAR, DOY, HPLC_CHLA) %>%
  dplyr::group_by(YEAR,DOY,LATDEC,LONGDEC) %>%
  dplyr::summarize_all(.fun=dplyr::first) %>%
  dplyr::ungroup() %>%
  dplyr::arrange(YEAR,DOY,DEPTH)
# add columns for satellite bin and distance to bin
sat_loc_df <- data.frame(bin=nwa_bins_4km, lon=nwa_lons_4km, lat=nwa_lats_4km, stringsAsFactors = FALSE)
is_loc_df <- in_situ_df %>% dplyr::distinct(LONGDEC, LATDEC)
is_loc_df <- dplyr::bind_cols(
  is_loc_df,
  lapply(1:nrow(is_loc_df),
    function(i) {
      is_lon <- is_loc_df$LONGDEC[i]
      is_lat <- is_loc_df$LATDEC[i]
      tmp_sat_df <- sat_loc_df %>% dplyr::filter(abs(lat - is_lat) < 1 & abs(lon - is_lon) < 1)
      tmp_sat_df$dist <- as.numeric(geodist(x=data.frame(lon=is_lon, lat=is_lat), y=tmp_sat_df %>% dplyr::select(lon, lat), measure="geodesic"))
      tmp_sat_df[which.min(tmp_sat_df$dist),c("dist","bin")]
    }) %>%
  do.call(rbind, .)
)
in_situ_df <- dplyr::left_join(in_situ_df, is_loc_df, by=c("LATDEC","LONGDEC")) %>%
  dplyr::mutate(week8 = week8(lubridate::as_date(paste(YEAR, DOY), format="%Y %j")),
                decimal_time = YEAR + (week8-1)/46,
                decimal_time_day = YEAR + (DOY-1)/ifelse(leap_year(YEAR),366,365)) %>%
  as.data.frame() %>%
  dplyr::filter(dist <= max_is_dist)

```

# Description

This displays the resulting filled images calculated using the `fill_gaps.R` script.  

Different parameters were tested on the following data (note there are 2 different weeks, one with good weekly coverage and one without):  

    Region: Northwest Atlantic (NWA, 39 to 82 N, 42 to 95 W)  
    Sensor: `r sensor`   
    Resolution: 4km   
    Processing level: Level 3, binned (L3b)  
    Year: `r year`  
    Weeks: `r paste0(weeks, collapse=", ")`  
    Pixels outside `r paste0(c(low_chla, high_chla), collapse="-")` mg m^-3 removed  
    Days with < `r low_percov`% coverage removed  

ImputeEOF removes randomly sampled valid pixels for cross-validation. The number of pixels used is the maximum of 30, or 10% of the pixels. The function continues adding EOFs and calculating the resulting RMSE between real and reconstructed cross-validation pixels until the difference between the current RMSE and RMSE of the previous iteration is below a certain threshold (i.e. adding the most recent EOF did not significantly improve the RMSE). The threshold, called the "tolerance", is different depending on whether you're filling data in linear space or in log space, since a log RMSE will be only a fraction of the size of a linear RMSE:  

Tolerance for filling logged data: 0.001  
Tolerance for filling linear data: 0.01  

We start by using a year of data to fill the gaps, and compare different methods below. Then, using the best options, we'll try using a longer time series.  

For each method of filling gaps, we'll examine the following:  

  - original image(s) vs filled image(s)  
  - 2 separate maps: one early in the year and one later, to check performance on days with low and medium/high spatial coverage  
  - linear regression of filled pixels vs original pixels (in log space) using randomly-spaced cross-validation pixels  
  - various metrics:  
      - RMSE and number of EOFs used  
      - R^2, p-value, number of observations (nobs), intercept, and slope of the cross-validation regression  
  - linear regression of in situ samples VS filled satellite data (in situ samples restricted to matches <= `r max_is_dist/1000` km away)  

The linear regression uses the standard major axis method (SMA) from `lmodel2::lmodel2()`, since it minimizes the area of the triangle instead of the distance in the x or y direction alone (i.e. it assumes there is error in both the independent and dependent variables, the "real" and filled/reconstructed data).  

Also note that for the tests that involve filling an 8day composite, in situ matchups should be interpreted with caution because of the long temporal bin and the changes that could occur in concentrations and patterns within that time span.  


An analysis of DINEOF on the Canadian Pacific coast:  
[Hilborn A, Costa M. Applications of DINEOF to Satellite-Derived Chlorophyll-a from a Productive Coastal Region. Remote Sensing. 2018; 10(9):1449. https://doi.org/10.3390/rs10091449](https://www.mdpi.com/2072-4292/10/9/1449)  




# 8day vs daily

Chla algorithm: OCx  
Logged/linear data: Logged  

Which is better - filling the gaps in 8day data, or filling gaps in daily data and then averaging it into an 8day image?  

Although some R^2 metrics are higher for the daily filled version, and the RMSE for the total series and the week with good percent coverage are slightly lower, overall the 8day cross-validation data has a better fit and less bias (e.g. it identifies some patterns of higher concentration better than the daily fill), and gives a better reconstruction for weeks with poor percent coverage.  


#### <b>8day</b>

```{r}

variable <- "CHL_OCX"
region <- "PANCAN"
fill_log <- TRUE
composite <- "8day"
input_years <- ifelse(num_years==0, year, paste0(range(plus_minus(year,num_years)), collapse="-"))
input_name <- paste0("method_testing_output/filled_", region, "_", sensor, "_", variable, "_", input_years, "_")

tsc <- time_series_comparison(variable=variable,
                              region=region,
                              fill_log=fill_log,
                              composite=composite,
                              num_years=0,
                              times=weeks)
attr_df <- tsc$attr_df
week_rmses <- tsc$time_rmses

display_rmse(attr_df, weeks, week_rmses)
grid.arrange(grobs=tsc[1:6], nrow=2)

```

#### <b>Daily</b>

```{r}

composite <- "daily"
file <- paste0(input_name, composite, ifelse(fill_log, "_logged", ""), "_randomCVpts")
df <- as.data.table(read_fst(paste0(file, ".fst")))
load(paste0(file, "_attr.rda"))

days_in_the_week <- list(yday(week8_date(year,weeks[1])):(yday(week8_date(year,weeks[1]))+7),
                         yday(week8_date(year,weeks[2])):(yday(week8_date(year,weeks[2]))+7))
num_days <- dim(df)[1]/num_pix$NWA$`4km`
available_days <- as.integer(round(sort(unique((df$time-year)*ifelse(leap_year(year),366,365) + 1))))
mat_var <- matrix(df$var, ncol=num_days)
mat_var_imputed <- matrix(df$var_imputed, ncol=num_days)
map1 <- make_map(data.frame(bin=nwa_bins_4km,
                            var=rowMeans(mat_var[,available_days %in% days_in_the_week[[1]]], na.rm=TRUE),
                            var_imputed=rowMeans(mat_var_imputed[,available_days %in% days_in_the_week[[1]]], na.rm=TRUE),
                            stringsAsFactors = FALSE),
                title=paste0("Daily filled, then 8day avg - week ",weeks[1]),
                log_raster=TRUE)
map2 <- make_map(data.frame(bin=nwa_bins_4km,
                            var=rowMeans(mat_var[,available_days %in% days_in_the_week[[2]]], na.rm=TRUE),
                            var_imputed=rowMeans(mat_var_imputed[,available_days %in% days_in_the_week[[2]]], na.rm=TRUE),
                            stringsAsFactors = FALSE),
                title=paste0("Daily filled, then 8day avg - week ",weeks[2]),
                log_raster=TRUE)
# perform linear regression on cross-validation pixels, and extract stats
cv_df <- df %>% dplyr::filter(is.finite(validation_pixels))
lm_cv <- lmodel2(log10(validation_pixels) ~ log10(var), data=cv_df)
stats_df <- data.frame(matrix(c(as.numeric(broom::glance(lm_cv)[,c("r.squared", "p.value", "nobs")]),
                                as.numeric(unlist(broom::tidy(lm_cv)[5:6,"estimate"]))), ncol=1),
                       row.names=c("R^2", "p-value", "nobs", "intercept", "slope"),
                       stringsAsFactors = FALSE)
tab <- tableGrob(round(stats_df,3), cols=NULL)
p <- cv_plot(cv_df,stats_df[4,],stats_df[5,],tab,"Cross-validation pixel regression")

# do the same with individual selected weeks to test
week1_cv_df <- cv_df %>% dplyr::filter(time %in% (year + (days_in_the_week[[1]]-1)/ifelse(leap_year(year),366,365)))
week2_cv_df <- cv_df %>% dplyr::filter(time %in% (year + (days_in_the_week[[2]]-1)/ifelse(leap_year(year),366,365)))
if (fill_log) {
  week_rmses <- c(rmse(log10(week1_cv_df$var), log10(week1_cv_df$validation_pixels)),
                  rmse(log10(week2_cv_df$var), log10(week2_cv_df$validation_pixels)))
} else {
  week_rmses <- c(rmse(week1_cv_df$var, week1_cv_df$validation_pixels),
                  rmse(week2_cv_df$var, week2_cv_df$validation_pixels))
}
tab <- make_tab(y=log10(week1_cv_df$validation_pixels), x=log10(week1_cv_df$var))
p1 <- cv_plot(week1_cv_df,tab$stats_df[4,],tab$stats_df[5,],tab$tab,paste0("CV regression - week ", weeks[1]))
tab <- make_tab(y=log10(week2_cv_df$validation_pixels), x=log10(week2_cv_df$var))
p2 <- cv_plot(week2_cv_df,tab$stats_df[4,],tab$stats_df[5,],tab$tab,paste0("CV regression - week ", weeks[2]))

# remove repetitive axis titles/scales
p2 <- p2 + theme(axis.title.y=element_blank(), axis.text.y=element_blank())
p <- p + theme(axis.title.y=element_blank(), axis.text.y=element_blank())

matchups <- dplyr::left_join(df, in_situ_df %>% dplyr::rename(time=decimal_time_day), by=c("bin", "time")) %>%
  dplyr::filter(is.finite(ID)) %>%
  dplyr::rename(Real=var, Filled=validation_pixels) %>%
  tidyr::pivot_longer(cols=c(Real, Filled), names_to="Satellite", values_to="sat_chla", values_drop_na=TRUE) %>%
  dplyr::arrange(Satellite, time)

isp <- matchup_plot(matchups)

display_rmse(attr_df, weeks, week_rmses)
grid.arrange(grobs=list(map1,map2,isp,p1,p2,p), nrow=2)

```




# OCx vs POLY4

Temporal binning: 8day  
Logged/linear data: Logged  

Should the OCx or POLY4 algorithm be used? Note that POLY4 has shown to remove some of the bias in the NWA.  
OCx = global band-ratio  
POLY4 = regional band-ratio, tuned to NWA  

Although the POLY4 algorithm increases the RMSE, it also appears to remove some of the bias and provide a tighter fit around the 1:1 line of the CV regression, as well as improving the fit with the in situ matchups. POLY4 was tuned to remove the bias in the NWA that was present when using the OCx algorithm, creating a steeper gradient in chla concentration, which might explain the increase in RMSE as the higher range of chla could be harder to reconstruct.  


#### <b>OCx</b>

```{r}

tsc <- time_series_comparison(variable="CHL_OCX",
                              region="PANCAN",
                              fill_log=TRUE,
                              composite="8day",
                              num_years=0,
                              times=weeks)
attr_df <- tsc$attr_df
week_rmses <- tsc$time_rmses

display_rmse(attr_df, weeks, week_rmses)
grid.arrange(grobs=tsc[1:6], nrow=2)

```

#### <b>POLY4</b>

```{r}

tsc <- time_series_comparison(variable="CHL_POLY4",
                              region="NWA",
                              fill_log=TRUE,
                              composite="8day",
                              num_years=0,
                              times=weeks)
attr_df <- tsc$attr_df
week_rmses <- tsc$time_rmses

display_rmse(attr_df, weeks, week_rmses)
grid.arrange(grobs=tsc[1:6], nrow=2)

```




# Log vs linear

Temporal binning: 8day  
Chla algorithm: POLY4  

Should we use logged data or linear data to fill the gaps?  
Note the process for the log option:  

  - log the data
  - set values <= 0 to NA  
  - fill gaps using ImputeEOF()  
  - transform filled image back to linear space  

(Note that the RMSE is smaller when fitting logged data since it was calculated in log space)  

Logged data gives a smoother fill and better R^2 in the CV regressions as it is not negatively impacted by isolated spikes over relatively low and consistent concentrations.  


#### <b>Log</b>

```{r}

tsc <- time_series_comparison(variable="CHL_POLY4",
                              region="NWA",
                              fill_log=TRUE,
                              composite="8day",
                              num_years=0,
                              times=weeks)
attr_df <- tsc$attr_df
week_rmses <- tsc$time_rmses

display_rmse(attr_df, weeks, week_rmses)
grid.arrange(grobs=tsc[1:6], nrow=2)

```

#### <b>Linear</b>

```{r}

tsc <- time_series_comparison(variable="CHL_POLY4",
                              region="NWA",
                              fill_log=FALSE,
                              composite="8day",
                              num_years=0,
                              times=weeks)
attr_df <- tsc$attr_df
week_rmses <- tsc$time_rmses

display_rmse(attr_df, weeks, week_rmses)
grid.arrange(grobs=tsc[1:6], nrow=2)

```




# Longer time series

Temporal binning: 8day  
Chla algorithm: POLY4  
Logged/linear data: Logged  

If more satellite images are used in the algorithm, will it improve the results?  

Hilborn and Costa (2018) found that pixel reconstruction improved with more data in a smaller region on the Canadian Pacific coast. Up until this point we have only used one year of data to fill the gaps, but here we'll try adding more (an equal number of years on either side of the target year, `r year`).  

Note that the 3year/5year DINEOF runs use the same cross-validation pixels for `r year` with extra randomly-selected pixels from the remaining years. Also, the CV regression below is performed using only the CV pixels for `r year` to give a more accurate comparison between methods.  

Overall, expanding the time series gives a slight improvement to the results, most notably when using 3 years instead of a single year. Based on the RMSE summary plot at the bottom, a time series of 7 to 9 years could be used to get the optimal results, but the smaller decrease in RMSE with every added year might not be worth the extra processing time.  


#### <b>1 year</b>

```{r}

tsc <- time_series_comparison(variable="CHL_POLY4",
                              region="NWA",
                              fill_log=TRUE,
                              composite="8day",
                              num_years=0,
                              times=weeks)
attr_df <- tsc$attr_df
week_rmses <- tsc$time_rmses

stats_to_plot <- cbind(rep(1,5),
                       c("EOF", "RMSE", paste0("Week",weeks,"_RMSE"), "Processing_time"),
                       c(attr_df$eof, attr_df$rmse, week_rmses, attr_df$time_to_process))

display_rmse(attr_df, weeks, week_rmses)
grid.arrange(grobs=tsc[1:6], nrow=2)

```

#### <b>3 years</b>

```{r}

num_years <- 1
tsc <- time_series_comparison(variable="CHL_POLY4",
                              region="NWA",
                              fill_log=TRUE,
                              composite="8day",
                              num_years=num_years,
                              times=weeks)

attr_df <- tsc$attr_df
week_rmses <- tsc$time_rmses

stats_to_plot <- rbind(stats_to_plot,
                       cbind(rep(num_years*2+1,5),
                             c("EOF", "RMSE", paste0("Week",weeks,"_RMSE"), "Processing_time"),
                             c(attr_df$eof, attr_df$rmse, week_rmses, attr_df$time_to_process)))

display_rmse(attr_df, weeks, week_rmses)
grid.arrange(grobs=tsc[1:6], nrow=2)

```

#### <b>5 years</b>

```{r}

num_years <- 2
tsc <- time_series_comparison(variable="CHL_POLY4",
                              region="NWA",
                              fill_log=TRUE,
                              composite="8day",
                              num_years=num_years,
                              times=weeks)

attr_df <- tsc$attr_df
week_rmses <- tsc$time_rmses

stats_to_plot <- rbind(stats_to_plot,
                       cbind(rep(num_years*2+1,5),
                             c("EOF", "RMSE", paste0("Week",weeks,"_RMSE"), "Processing_time"),
                             c(attr_df$eof, attr_df$rmse, week_rmses, attr_df$time_to_process)))

display_rmse(attr_df, weeks, week_rmses)
grid.arrange(grobs=tsc[1:6], nrow=2)

```

#### <b>7 years</b>

```{r}

num_years <- 3
tsc <- time_series_comparison(variable="CHL_POLY4",
                              region="NWA",
                              fill_log=TRUE,
                              composite="8day",
                              num_years=num_years,
                              times=weeks)

attr_df <- tsc$attr_df
week_rmses <- tsc$time_rmses

stats_to_plot <- rbind(stats_to_plot,
                       cbind(rep(num_years*2+1,5),
                             c("EOF", "RMSE", paste0("Week",weeks,"_RMSE"), "Processing_time"),
                             c(attr_df$eof, attr_df$rmse, week_rmses, attr_df$time_to_process)))

display_rmse(attr_df, weeks, week_rmses)
grid.arrange(grobs=tsc[1:6], nrow=2)

```

#### <b>9 years</b>

```{r}

num_years <- 4
tsc <- time_series_comparison(variable="CHL_POLY4",
                              region="NWA",
                              fill_log=TRUE,
                              composite="8day",
                              num_years=num_years,
                              times=weeks)

attr_df <- tsc$attr_df
week_rmses <- tsc$time_rmses

stats_to_plot <- rbind(stats_to_plot,
                       cbind(rep(num_years*2+1,5),
                             c("EOF", "RMSE", paste0("Week",weeks,"_RMSE"), "Processing_time"),
                             c(attr_df$eof, attr_df$rmse, week_rmses, attr_df$time_to_process)))

display_rmse(attr_df, weeks, week_rmses)
grid.arrange(grobs=tsc[1:6], nrow=2)

```




#### <b>Summary</b>

```{r fig.width=10, fig.height=4}

stats_to_plot <- data.frame(stats_to_plot, stringsAsFactors = FALSE)
colnames(stats_to_plot) <- c("Number of years", "Statistic", "Value")
stats_to_plot$Value <- as.numeric(stats_to_plot$Value)
stats_to_plot$Statistic <- as.factor(stats_to_plot$Statistic)

cat("Number of EOFs for 1/3/5/7/9 years:", paste0((stats_to_plot %>% dplyr::filter(Statistic == "EOF"))$Value, collapse="/"))

prmse <- ggplot(stats_to_plot %>% dplyr::filter(!(Statistic %in% c("EOF", "Processing_time")))) +
  geom_point(aes(x=`Number of years`, y=Value, color=Statistic)) +
  geom_line(aes(x=`Number of years`, y=Value, color=Statistic, group=Statistic)) +
  theme_bw() +
  theme(axis.title.y=element_blank())

ptime <- ggplot(stats_to_plot %>% dplyr::filter(Statistic=="Processing_time")) +
  geom_point(aes(x=`Number of years`, y=Value/60, group=1)) +
  geom_line(aes(x=`Number of years`, y=Value/60, group=1)) +
  theme_bw() +
  labs(y="Processing time\n(minutes)")

print(ptime + prmse)

```
